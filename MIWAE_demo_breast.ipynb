{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIWAE_demo_breast",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21Vl-BrWuKLL",
        "colab_type": "text"
      },
      "source": [
        "# Deep learning meets missing data: Doing it MIWAE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMq1ifa_uUna",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, we'll show how to learn a deep generative model on a small and **incomplete** continuous data set. We will also show how to **impute** the missing values of this data set. \n",
        "\n",
        "This is based on the following paper, available [on arXiv](https://arxiv.org/abs/1812.02633):\n",
        "\n",
        "P.-A. Mattei & J. Frellsen, **MIWAE: Deep Generative Modelling and Imputation of Incomplete Data Sets**, *International Conference on Machine Learning*, in press (2019)\n",
        "\n",
        "It is possible to run this notebook in Google Colab, which allows to benefit from free GPU computing.\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "    <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/pamattei/MIWAE_demo_breast.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dawQVMWrvxYu",
        "colab_type": "text"
      },
      "source": [
        "# Installing and loading useful stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dymypuAny4P",
        "colab_type": "code",
        "outputId": "a2ac8133-eca7-45cf-89c2-7a0ae4e45d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip3 install --user --upgrade scikit-learn # We need to update it to run missForest\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import scipy.io\n",
        "import scipy.sparse\n",
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.impute import SimpleImputer\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.21.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.12.5)\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWcQ9yIFXUTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse(xhat,xtrue,mask): # MSE function for imputations\n",
        "    xhat = np.array(xhat)\n",
        "    xtrue = np.array(xtrue)\n",
        "    return np.mean(np.power(xhat-xtrue,2)[~mask])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RpNVgHjuPzC",
        "colab_type": "text"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeBa5C1WXoGN",
        "colab_type": "text"
      },
      "source": [
        "We'll use the breast cancer data set from scikit-learn.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIQ9W-Uv_ur0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer(True)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxWks15H_GOB",
        "colab_type": "text"
      },
      "source": [
        "It is also possible to use the \"white wine\" or \"red wine\" UCI data sets by uncommenting one of the following cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ImVc9R52qdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
        "#data = np.array(pd.read_csv(url, low_memory=False, sep=';'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akd4tc0m-HMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
        "#data = np.array(pd.read_csv(url, low_memory=False, sep=';'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SISFvaO_SJ2",
        "colab_type": "text"
      },
      "source": [
        "We now standardise the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp_Xbte_2zVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xfull = (data - np.mean(data,0))/np.std(data,0)\n",
        "n = xfull.shape[0] # number of observations\n",
        "p = xfull.shape[1] # number of features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ct5EDgdXxJD",
        "colab_type": "text"
      },
      "source": [
        "We will remove uniformy at random 50% of the data. This corresponds to a *missing completely at random (MCAR)* scenario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8A94e8tX8ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)\n",
        "\n",
        "perc_miss = 0.5 # 50% of missing data\n",
        "xmiss = np.copy(xfull)\n",
        "xmiss_flat = xmiss.flatten()\n",
        "miss_pattern = np.random.choice(n*p, np.floor(n*p*perc_miss).astype(np.int), replace=False)\n",
        "xmiss_flat[miss_pattern] = np.nan \n",
        "xmiss = xmiss_flat.reshape([n,p]) # in xmiss, the missing values are represented by nans\n",
        "mask = np.isfinite(xmiss) # binary mask that indicates which values are missing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj0YaRppuvw4",
        "colab_type": "text"
      },
      "source": [
        "A simple way of imputing the incomplete data is to replace the missing values by zeros. This x_hat0 is what will be fed to our encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PorBq9ncYZ8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xhat_0 = np.copy(xmiss)\n",
        "xhat_0[np.isnan(xmiss)] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5uWZxzLYns_",
        "colab_type": "text"
      },
      "source": [
        "# Placeholders and hyperparemeters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo-L63QRYaGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, p]) # Placeholder for xhat_0\n",
        "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
        "batch_size = tf.shape(x)[0]\n",
        "xmask = tf.placeholder(tf.bool, shape=[None, p])\n",
        "K= tf.placeholder(tf.int32, shape=[]) # Placeholder for the number of importance weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFQ7OsOJYwYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h = 128 # number of hidden units in (same for all MLPs)\n",
        "d = 10 # dimension of the latent space"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srUk6d53ZCJT",
        "colab_type": "text"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zepRWE3kDI_-",
        "colab_type": "text"
      },
      "source": [
        "$$p(\\mathbf{x}_1,...,\\mathbf{x}_n) = \\prod_{i=1}^n p(\\mathbf{x}_i|\\mathbf{z}_i)p(\\mathbf{z}_i)$$\n",
        "$$p(\\mathbf{z}_i) = \\mathcal{N}(\\mathbf{z}_i|\\mathbf{0}_d,\\mathbf{I}_d) $$\n",
        "$$p(\\mathbf{x}_i|\\mathbf{z}_i) = \\text{St} (\\mathbf{x}_i|\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z}_i),\\boldsymbol{\\sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}_i),\\boldsymbol{\\nu}_{\\boldsymbol{\\theta}}(\\mathbf{z}_i))$$\n",
        "\n",
        "$$f_{\\boldsymbol{\\theta}} (\\mathbf{z})=\\sigma(\\mathbf{W}_1\\sigma(\\mathbf{W}_0\\mathbf{z}+\\mathbf{b}_0)+\\mathbf{b}_1) $$\n",
        "\n",
        "$$\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z}) = \\mathbf{W}_\\boldsymbol{\\mu}f_{\\boldsymbol{\\theta}} (\\mathbf{z})+\\mathbf{b}_\\boldsymbol{\\mu} $$\n",
        "\n",
        "$$\\boldsymbol{\\sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}) = \\text{Softplus}(\\mathbf{W}_\\boldsymbol{\\sigma}f_{\\boldsymbol{\\theta}} (\\mathbf{z})+\\mathbf{b}_\\boldsymbol{\\sigma}) + 0.0001 $$\n",
        "\n",
        "$$\\boldsymbol{\\nu}_{\\boldsymbol{\\theta}}(\\mathbf{z}) = \\text{Softplus}(\\mathbf{W}_\\boldsymbol{\\nu}f_{\\boldsymbol{\\theta}} (\\mathbf{z})+\\mathbf{b}_\\boldsymbol{\\nu}) + 3 $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYZUCY4OYwiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_z = tfd.MultivariateNormalDiag(loc=tf.zeros(d, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3OpwDjthBWn",
        "colab_type": "code",
        "outputId": "53762df9-16c8-42a7-e27c-fe3081689d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "decoder = tfk.Sequential([\n",
        "  tfkl.InputLayer(input_shape=[d,]),\n",
        "  tfkl.Dense(h, activation='tanh',kernel_initializer=\"orthogonal\"),\n",
        "  tfkl.Dense(h, activation='tanh',kernel_initializer=\"orthogonal\"),\n",
        "  tfkl.Dense(3*p,kernel_initializer=\"orthogonal\") # the decoder will output both the mean, the scale, and the number of degrees of freedoms (hence the 3*p)\n",
        "])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evV7W4TikheZ",
        "colab_type": "text"
      },
      "source": [
        "#Building the inference network (*aka* encoder)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAIuTL91I1MJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tiledmask = tf.tile(xmask,[K,1])\n",
        "tiledmask_float = tf.cast(tiledmask,tf.float32)\n",
        "mask_not_float = tf.abs(-tf.cast(xmask,tf.float32))\n",
        "\n",
        "iota = tf.Variable(np.zeros([1,p]),dtype=tf.float32)\n",
        "tilediota = tf.tile(iota,[batch_size,1])\n",
        "iotax = x + tf.multiply(tilediota,mask_not_float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LvjgC87koO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = tfk.Sequential([\n",
        "  tfkl.InputLayer(input_shape=[p,]),\n",
        "  tfkl.Dense(h, activation='tanh',kernel_initializer=\"orthogonal\"),\n",
        "  tfkl.Dense(h, activation='tanh',kernel_initializer=\"orthogonal\"),\n",
        "  tfkl.Dense(3*d,kernel_initializer=\"orthogonal\")\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGVLDugmloFM",
        "colab_type": "text"
      },
      "source": [
        "#Building the MIWAE loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO23BaO_nQ0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_encoder = encoder(iotax)\n",
        "q_zgivenxobs = tfd.Independent(distribution=tfd.StudentT(loc=out_encoder[..., :d], scale=tf.nn.softplus(out_encoder[..., d:(2*d)]), df=3 + tf.nn.softplus(out_encoder[..., (2*d):(3*d)])))\n",
        "zgivenx = q_zgivenxobs.sample(K)\n",
        "zgivenx_flat = tf.reshape(zgivenx,[K*batch_size,d])\n",
        "data_flat = tf.reshape(tf.tile(x,[K,1]),[-1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA8IHHr-lso-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_decoder = decoder(zgivenx_flat)\n",
        "all_means_obs_model = out_decoder[..., :p]\n",
        "all_scales_obs_model = tf.nn.softplus(out_decoder[..., p:(2*p)]) + 0.0001\n",
        "all_degfreedom_obs_model = tf.nn.softplus(out_decoder[..., (2*p):(3*p)]) + 3\n",
        "all_log_pxgivenz_flat = tfd.StudentT(loc=tf.reshape(all_means_obs_model,[-1,1]),scale=tf.reshape(all_scales_obs_model,[-1,1]),df=tf.reshape(all_degfreedom_obs_model,[-1,1])).log_prob(data_flat)\n",
        "all_log_pxgivenz = tf.reshape(all_log_pxgivenz_flat,[K*batch_size,p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzYf9fwzls12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logpxobsgivenz = tf.reshape(tf.reduce_sum(tf.multiply(all_log_pxgivenz,tiledmask_float),1),[K,batch_size])\n",
        "logpz = p_z.log_prob(zgivenx)\n",
        "logq = q_zgivenxobs.log_prob(zgivenx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxdFDGlKltCy",
        "colab_type": "code",
        "outputId": "57841af3-efb5-47aa-ec6e-3700d380e091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "miwae_loss = -tf.reduce_mean(tf.reduce_logsumexp(logpxobsgivenz + logpz - logq,0)) +tf.log(tf.cast(K,tf.float32))\n",
        "train_miss = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(miwae_loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUWloElrESwP",
        "colab_type": "text"
      },
      "source": [
        "# Single imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AE5q7QraifH",
        "colab_type": "text"
      },
      "source": [
        "\\begin{equation}\n",
        "\\mathbb E [\\mathbf{x}^{\\text{m}} | \\mathbf{x}^{\\text{o}}] \\approx \\sum_{l=1}^L w_l \\mathbb{E}\\left[\\mathbf{x}^{\\text{m}} | \\mathbf{x}^{\\text{o}},\\mathbf{z}_{(l)}\\right],\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "w_l=\\frac{r_l}{r_1+...+r_L}, \\; \\text{with} \\; r_l = \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}^{\\text{o}}|\\mathbf{z}_{(l)})p(\\mathbf{z}_{(l)})}{q_{\\boldsymbol{\\gamma}}(\\mathbf{z}_{(l)}|\\mathbf{x}^{\\text{o}})}.\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saR4UBU7E8IN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgivenz = tfd.Independent(\n",
        "      distribution=tfd.StudentT(loc=all_means_obs_model, scale=all_scales_obs_model, df=all_degfreedom_obs_model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZyjTXuuEX0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imp_weights = tf.nn.softmax(logpxobsgivenz + logpz - logq,0) # these are w_1,....,w_L for all observations in the batch\n",
        "xms = tf.reshape(xgivenz.sample(),[K,batch_size,p])\n",
        "xm=tf.einsum('ki,kij->ij', imp_weights, xms) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7zfAGIjHt_k",
        "colab_type": "text"
      },
      "source": [
        "# Training and imputing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTQF_6D1n4Lm",
        "colab_type": "code",
        "outputId": "6dbf62d1-b7bb-47e6-a54b-cde35cde5dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "miwae_loss_train=np.array([])\n",
        "mse_train=np.array([])\n",
        "bs = 64 # batch size\n",
        "n_epochs = 602\n",
        "xhat = np.copy(xhat_0) # This will be out imputed data matrix\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for ep in range(1,n_epochs):\n",
        "      perm = np.random.permutation(n) # We use the \"random reshuffling\" version of SGD\n",
        "      batches_data = np.array_split(xhat_0[perm,], n/bs)\n",
        "      batches_mask = np.array_split(mask[perm,], n/bs)\n",
        "      for it in range(len(batches_data)):\n",
        "          train_miss.run(feed_dict={x: batches_data[it], learning_rate: 0.001, K:20, xmask: batches_mask[it]}) # Gradient step      \n",
        "      if ep % 200 == 1:\n",
        "          losstrain = np.array([miwae_loss.eval(feed_dict={x: xhat_0, K:20, xmask: mask})]) # MIWAE bound evaluation\n",
        "          miwae_loss_train = np.append(miwae_loss_train,-losstrain,axis=0)\n",
        "          print('Epoch %g' %ep)\n",
        "          print('MIWAE likelihood bound  %g' %-losstrain)\n",
        "          for i in range(n): # We impute the observations one at a time for memory reasons\n",
        "              xhat[i,:][~mask[i,:]]=xm.eval(feed_dict={x: xhat_0[i,:].reshape([1,p]), K:1000, xmask: mask[i,:].reshape([1,p])})[~mask[i,:].reshape([1,p])]\n",
        "          err = np.array([mse(xhat,xfull,mask)])\n",
        "          mse_train = np.append(mse_train,err,axis=0)\n",
        "          print('Imputation MSE  %g' %err)\n",
        "          print('-----')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "MIWAE likelihood bound  -19.0619\n",
            "Imputation MSE  0.826288\n",
            "-----\n",
            "Epoch 201\n",
            "MIWAE likelihood bound  -7.5512\n",
            "Imputation MSE  0.332653\n",
            "-----\n",
            "Epoch 401\n",
            "MIWAE likelihood bound  -6.42971\n",
            "Imputation MSE  0.306531\n",
            "-----\n",
            "Epoch 601\n",
            "MIWAE likelihood bound  -5.24136\n",
            "Imputation MSE  0.300238\n",
            "-----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZsYAmymH28c",
        "colab_type": "text"
      },
      "source": [
        "# Comparisons with other methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84kWm6OVIRq8",
        "colab_type": "text"
      },
      "source": [
        "We make use of the recent [IterativeImputer](https://scikit-learn.org/dev/auto_examples/impute/plot_iterative_imputer_variants_comparison.html) mehod implemented in scikit-learn. It allows, in particular, to use an imputation technique quite similar to the popular missForest algorithm of  [Stekhoven & Bühlmann (2011)](https://academic.oup.com/bioinformatics/article/28/1/112/219101)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQMQZzoqEXxw",
        "colab_type": "code",
        "outputId": "d47c83ad-f1ad-4c01-8177-348956d1e532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "missforest = IterativeImputer(estimator=ExtraTreesRegressor(n_estimators=100))\n",
        "iterative_ridge = IterativeImputer(estimator=BayesianRidge())\n",
        "missforest.fit(xmiss)\n",
        "iterative_ridge.fit(xmiss)\n",
        "xhat_mf = missforest.transform(xmiss)\n",
        "xhat_ridge = iterative_ridge.transform(xmiss)\n",
        "mean_imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "mean_imp.fit(xmiss)\n",
        "xhat_mean = mean_imp.transform(xmiss)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:599: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  \" reached.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF3VgTEGEXu-",
        "colab_type": "code",
        "outputId": "72054ab3-0aa5-473f-e7cc-53a8373763e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(range(1,n_epochs,200),mse_train,color=\"blue\")\n",
        "plt.axhline(y=mse(xhat_mf,xfull,mask),  linestyle='-',color=\"red\")\n",
        "plt.axhline(y=mse(xhat_ridge,xfull,mask),  linestyle='-',color=\"orange\")\n",
        "plt.legend([\"MIWAE\",\"missForest\",\"Iterative ridge\"])\n",
        "plt.title(\"Imputation MSE\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noP8PkRImYFpQdHEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSkRyppXM_8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}