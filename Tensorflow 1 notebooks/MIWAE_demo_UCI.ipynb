{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIWAE_demo_UCI",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21Vl-BrWuKLL",
        "colab_type": "text"
      },
      "source": [
        "# Deep learning meets missing data: Doing it MIWAE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMq1ifa_uUna",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, we'll show how to learn a deep generative model on a small and **incomplete** continuous data set. We will also show how to **impute** the missing values of this data set. \n",
        "\n",
        "This is based on the following paper, available [on arXiv](https://arxiv.org/abs/1812.02633):\n",
        "\n",
        "P.-A. Mattei & J. Frellsen, **MIWAE: Deep Generative Modelling and Imputation of Incomplete Data Sets**, *Proceedings of the 36th International Conference on Machine Learning*, PMLR 97:4413-4423, 2019.\n",
        "\n",
        "It is possible to run this notebook in Google Colab, which allows to benefit from free GPU computing.\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "    <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/pamattei/MIWAE_demo_UCI.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dawQVMWrvxYu",
        "colab_type": "text"
      },
      "source": [
        "# Installing and loading useful stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dymypuAny4P",
        "colab_type": "code",
        "outputId": "a6b9e28f-321e-4727-be03-2550dacfdeae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip3 install --user --upgrade scikit-learn # We need to update it to run missForest\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import scipy.io\n",
        "import scipy.sparse\n",
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.impute import SimpleImputer\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.21.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.13.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.16.4)\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWcQ9yIFXUTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse(xhat,xtrue,mask): # MSE function for imputations\n",
        "    xhat = np.array(xhat)\n",
        "    xtrue = np.array(xtrue)\n",
        "    return np.mean(np.power(xhat-xtrue,2)[~mask])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RpNVgHjuPzC",
        "colab_type": "text"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeBa5C1WXoGN",
        "colab_type": "text"
      },
      "source": [
        "We'll use the Boston data set from scikit-learn:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOeApHbaVSIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "data = load_boston(True)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTtS1FJQjw3P",
        "colab_type": "text"
      },
      "source": [
        "It is also possible to use the Iris or the Breast cancer data sets by uncommenting one of the following cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RtDGEQjWNW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn.datasets import load_iris\n",
        "#data = load_iris(True)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qZQA7peYNI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn.datasets import load_breast_cancer\n",
        "#data = load_breast_cancer(True)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxWks15H_GOB",
        "colab_type": "text"
      },
      "source": [
        "It is also possible to use the \"white wine\", \"red wine\", or \"banknote\" UCI data sets by uncommenting one of the following cells:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ImVc9R52qdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
        "#data = np.array(pd.read_csv(url, low_memory=False, sep=';'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akd4tc0m-HMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
        "#data = np.array(pd.read_csv(url, low_memory=False, sep=';'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiX9pkXkhG9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\"\n",
        "#data = np.array(pd.read_csv(url, low_memory=False, sep=','))[:,0:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SISFvaO_SJ2",
        "colab_type": "text"
      },
      "source": [
        "We now standardise the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp_Xbte_2zVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xfull = (data - np.mean(data,0))/np.std(data,0)\n",
        "n = xfull.shape[0] # number of observations\n",
        "p = xfull.shape[1] # number of features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ct5EDgdXxJD",
        "colab_type": "text"
      },
      "source": [
        "We will remove uniformy at random 50% of the data. This corresponds to a *missing completely at random (MCAR)* scenario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8A94e8tX8ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)\n",
        "\n",
        "perc_miss = 0.5 # 50% of missing data\n",
        "xmiss = np.copy(xfull)\n",
        "xmiss_flat = xmiss.flatten()\n",
        "miss_pattern = np.random.choice(n*p, np.floor(n*p*perc_miss).astype(np.int), replace=False)\n",
        "xmiss_flat[miss_pattern] = np.nan \n",
        "xmiss = xmiss_flat.reshape([n,p]) # in xmiss, the missing values are represented by nans\n",
        "mask = np.isfinite(xmiss) # binary mask that indicates which values are missing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj0YaRppuvw4",
        "colab_type": "text"
      },
      "source": [
        "A simple way of imputing the incomplete data is to replace the missing values by zeros. This x_hat0 is what will be fed to our encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PorBq9ncYZ8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xhat_0 = np.copy(xmiss)\n",
        "xhat_0[np.isnan(xmiss)] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5uWZxzLYns_",
        "colab_type": "text"
      },
      "source": [
        "# Placeholders and hyperparemeters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo-L63QRYaGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, p]) # Placeholder for xhat_0\n",
        "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
        "batch_size = tf.shape(x)[0]\n",
        "xmask = tf.placeholder(tf.bool, shape=[None, p])\n",
        "K= tf.placeholder(tf.int32, shape=[]) # Placeholder for the number of importance weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srUk6d53ZCJT",
        "colab_type": "text"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zepRWE3kDI_-",
        "colab_type": "text"
      },
      "source": [
        "We will use a **deep latent variable model with a Gaussian prior and a Student's t observation model**. This can be written:\n",
        "\n",
        "$$p(\\mathbf{x}_1,...,\\mathbf{x}_n) = \\prod_{i=1}^n p(\\mathbf{x}_i|\\mathbf{z}_i)p(\\mathbf{z}_i),$$\n",
        "$$p(\\mathbf{z}_i) = \\mathcal{N}(\\mathbf{z}_i|\\mathbf{0}_d,\\mathbf{I}_d), $$\n",
        "$$p(\\mathbf{x}_i|\\mathbf{z}_i) = \\text{St} (\\mathbf{x}_i|\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z}_i),\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}_i),\\boldsymbol{\\nu}_{\\boldsymbol{\\theta}}(\\mathbf{z}_i)),$$\n",
        "\n",
        "where $\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}: \\mathbb{R}^d \\rightarrow \\mathbb{R}^p$, $\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}: \\mathbb{R}^d \\rightarrow \\mathcal{S}_p^{++}$, and $\\boldsymbol{\\nu}_{\\boldsymbol{\\theta}}: \\mathbb{R}^d \\rightarrow \\mathbb{R}_+^p$ are functions parametrised by deep neural nets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQGrEj5flTeK",
        "colab_type": "text"
      },
      "source": [
        "The weights of these nets are stored in a parameter $\\boldsymbol{\\theta}$. We choose to use the following simple architecture, where the 3 neural nets share the first layers:\n",
        "$$f_{\\boldsymbol{\\theta}} (\\mathbf{z})=\\sigma(\\mathbf{W}_1\\sigma(\\mathbf{W}_0\\mathbf{z}+\\mathbf{b}_0)+\\mathbf{b}_1) $$\n",
        "\n",
        "$$\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z}) = \\mathbf{W}_\\boldsymbol{\\mu}f_{\\boldsymbol{\\theta}} (\\mathbf{z})+\\mathbf{b}_\\boldsymbol{\\mu}, $$\n",
        "\n",
        "$$\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}) = \\text{Diag}\\left(\\text{Softplus}(\\mathbf{W}_\\boldsymbol{\\sigma}f_{\\boldsymbol{\\theta}} (\\mathbf{z})+\\mathbf{b}_\\boldsymbol{\\sigma}) + 10^{-3}\\right), $$\n",
        "\n",
        "$$\\boldsymbol{\\nu}_{\\boldsymbol{\\theta}}(\\mathbf{z}) = \\text{Softplus}(\\mathbf{W}_\\boldsymbol{\\nu}f_{\\boldsymbol{\\theta}} (\\mathbf{z})+\\mathbf{b}_\\boldsymbol{\\nu}) + 3. $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Tw89qNmLte",
        "colab_type": "text"
      },
      "source": [
        "A few **non-essential remarks** about this architecture:\n",
        "\n",
        "* This parametrisation is quite close to the one we use in the MIWAE paper. The main difference is that we use $\\sigma = \\text{ReLU}$ (which leads to faster training) while we used $\\sigma = \\text{tanh}$ in the paper.\n",
        "*   We use a [location-scale parametrisation](https://en.wikipedia.org/wiki/Location%E2%80%93scale_family) of the t distribution, following [the parametrisation available in TensorFlow](https://www.tensorflow.org/api_docs/python/tf/distributions/StudentT). Note in particular that $\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z})$ is not the covariance matrix of $\\mathbf{x} | \\mathbf{z}$. When it exitsts, the actual covariance matrix is diagonal with diagonal  $$ \\frac{\\text{diag}(\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}} (\\mathbf{z}))^2 \\boldsymbol{\\nu}_{\\boldsymbol{\\theta}}(\\mathbf{z})}{\\boldsymbol{\\nu}_{\\boldsymbol{\\theta}}(\\mathbf{z})-2}$$ (where all operations are made entrywise).\n",
        "*   The fact that the covariance matrix is diagonal means that we assume that **the features are independent conditionnally on the latent variable** (which is customary for DLVMs).\n",
        "* We add $3$ to the neural net that outputs the degrees of freedom. This is to guarantee that the tails of $p_{\\boldsymbol{\\theta}}(\\mathbf{x} | \\mathbf{z})$ are not too heavy. Indeed, having too heavy tails might imply that the mean of $p_{\\boldsymbol{\\theta}}(\\mathbf{x} | \\mathbf{z})$ does not exist! Adding 3 implies that the degrees of freedom is always larger than 3, implying in turn that **at least the first 3 moments of $p_{\\boldsymbol{\\theta}}(\\mathbf{x} | \\mathbf{z})$ are well-defined.**\n",
        "* We add $10^{-3}$ to the diagonal entries of $\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}$ to prevent singularities, [as advocated in our NeurIPS 2018 paper](https://papers.nips.cc/paper/7642-leveraging-the-exact-likelihood-of-deep-latent-variable-models). Why $10^{-3}$ specifically? Because, since the data have unit variance, this will imply that the latent variable explains at most $99.9999\\%$ of the variance of the data, which does not seem too restrictive. **This choice might be poor if the data are not standardised.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh_slL43JnLR",
        "colab_type": "text"
      },
      "source": [
        "We begin with the prior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYZUCY4OYwiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = np.floor(p/2).astype(int) # dimension of the latent space\n",
        "\n",
        "p_z = tfd.MultivariateNormalDiag(loc=tf.zeros(d, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KBnFeeMJ5S6",
        "colab_type": "text"
      },
      "source": [
        " Now, we define the **decoder**, which will be the backbone of the three functions $\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}: \\mathbb{R}^d \\rightarrow \\mathbb{R}^p$, $\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}: \\mathbb{R}^d \\rightarrow \\mathcal{S}_p^{++}$, and $\\boldsymbol{\\nu}_{\\boldsymbol{\\theta}}: \\mathbb{R}^d \\rightarrow \\mathbb{R}_+^p$. Here, the output space of this decoder is $\\mathbb{R}^{3p}$. Some additional operations are needed for $\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}: \\mathbb{R}^d \\rightarrow \\mathcal{S}_p^{++}$, and $\\boldsymbol{\\nu}_{\\boldsymbol{\\theta}}: \\mathbb{R}^d \\rightarrow \\mathbb{R}_+^p$, but it'll be more convenient to implement them later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3OpwDjthBWn",
        "colab_type": "code",
        "outputId": "0a9e8df0-e8fc-4814-d541-c363f3488153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "h = 128 # number of hidden units (same for all MLPs)\n",
        "\n",
        "sigma = \"relu\"\n",
        "\n",
        "decoder = tfk.Sequential([\n",
        "  tfkl.InputLayer(input_shape=[d,]),\n",
        "  tfkl.Dense(h, activation=sigma,kernel_initializer=\"orthogonal\"),\n",
        "  tfkl.Dense(h, activation=sigma,kernel_initializer=\"orthogonal\"),\n",
        "  tfkl.Dense(3*p,kernel_initializer=\"orthogonal\") # the decoder will output both the mean, the scale, and the number of degrees of freedoms (hence the 3*p)\n",
        "])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evV7W4TikheZ",
        "colab_type": "text"
      },
      "source": [
        "#Building the inference network (*aka* encoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf7M131MFq4G",
        "colab_type": "text"
      },
      "source": [
        "We will build a Student's t posterior approximation by using an **encoder** that mimicks the architecture of the decoder.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUpssvyaF83k",
        "colab_type": "text"
      },
      "source": [
        "The imputation function $\\iota$ replaces the missing values by learned constants. Note that this is slightly more general than what we use in the paper (which was just replacing missing values by zeros)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAIuTL91I1MJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tiledmask = tf.tile(xmask,[K,1])\n",
        "tiledmask_float = tf.cast(tiledmask,tf.float32)\n",
        "mask_not_float = tf.abs(-tf.cast(xmask,tf.float32))\n",
        "\n",
        "iota = tf.Variable(np.zeros([1,p]),dtype=tf.float32)\n",
        "tilediota = tf.tile(iota,[batch_size,1])\n",
        "iotax = x + tf.multiply(tilediota,mask_not_float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LvjgC87koO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = tfk.Sequential([\n",
        "  tfkl.InputLayer(input_shape=[p,]),\n",
        "  tfkl.Dense(h, activation=sigma,kernel_initializer=\"orthogonal\"),\n",
        "  tfkl.Dense(h, activation=sigma,kernel_initializer=\"orthogonal\"),\n",
        "  tfkl.Dense(3*d,kernel_initializer=\"orthogonal\")\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGVLDugmloFM",
        "colab_type": "text"
      },
      "source": [
        "#Building the MIWAE bound"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Q5jOGgG_GE",
        "colab_type": "text"
      },
      "source": [
        "We define the MIWAE bound:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnkox7-Q8hkA",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "\\mathcal{L}_K (\\boldsymbol{\\theta,\\gamma}) = \\sum_{i=1}^n \\mathbb{E}_{\\mathbf{z}_{i1},\\ldots,\\mathbf{z}_{iK} \\sim q_{\\boldsymbol{\\gamma}}(\\mathbf{z}|\\mathbf{x}^\\text{o}_i)} \\left[ \\log\\frac{1}{K} \\sum_{k=1}^K \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}_i^\\text{o}|\\mathbf{z}_{ik})p(\\mathbf{z}_{ik})}{q_{\\boldsymbol{\\gamma}}(\\mathbf{z}_{ik}|\\mathbf{x}^\\text{o}_i)} \\right].\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO23BaO_nQ0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_encoder = encoder(iotax)\n",
        "q_zgivenxobs = tfd.Independent(distribution=tfd.StudentT(loc=out_encoder[..., :d], scale=tf.nn.softplus(out_encoder[..., d:(2*d)]), df=3 + tf.nn.softplus(out_encoder[..., (2*d):(3*d)])))\n",
        "zgivenx = q_zgivenxobs.sample(K)\n",
        "zgivenx_flat = tf.reshape(zgivenx,[K*batch_size,d])\n",
        "data_flat = tf.reshape(tf.tile(x,[K,1]),[-1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA8IHHr-lso-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_decoder = decoder(zgivenx_flat)\n",
        "all_means_obs_model = out_decoder[..., :p]\n",
        "all_scales_obs_model = tf.nn.softplus(out_decoder[..., p:(2*p)]) + 0.001\n",
        "all_degfreedom_obs_model = tf.nn.softplus(out_decoder[..., (2*p):(3*p)]) + 3\n",
        "all_log_pxgivenz_flat = tfd.StudentT(loc=tf.reshape(all_means_obs_model,[-1,1]),scale=tf.reshape(all_scales_obs_model,[-1,1]),df=tf.reshape(all_degfreedom_obs_model,[-1,1])).log_prob(data_flat)\n",
        "all_log_pxgivenz = tf.reshape(all_log_pxgivenz_flat,[K*batch_size,p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzYf9fwzls12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logpxobsgivenz = tf.reshape(tf.reduce_sum(tf.multiply(all_log_pxgivenz,tiledmask_float),1),[K,batch_size])\n",
        "logpz = p_z.log_prob(zgivenx)\n",
        "logq = q_zgivenxobs.log_prob(zgivenx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxdFDGlKltCy",
        "colab_type": "code",
        "outputId": "17f5c38c-df93-4442-ea65-b64f611eb934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "miwae_loss = -tf.reduce_mean(tf.reduce_logsumexp(logpxobsgivenz + logpz - logq,0)) +tf.log(tf.cast(K,tf.float32))\n",
        "train_miss = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(miwae_loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUWloElrESwP",
        "colab_type": "text"
      },
      "source": [
        "# Single imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeyLR4l6HLgo",
        "colab_type": "text"
      },
      "source": [
        "The optimal (in the $\\ell_2$ sense) single imputation is the conditional mean $\\mathbb{E} [\\mathbf{x}^{\\text{m}} | \\mathbf{x}^{\\text{o}}]$. This can be estiamated using importance sampling:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AE5q7QraifH",
        "colab_type": "text"
      },
      "source": [
        "\\begin{equation}\n",
        "\\mathbb E [\\mathbf{x}^{\\text{m}} | \\mathbf{x}^{\\text{o}}] \\approx \\sum_{l=1}^L w_l \\mathbb{E}\\left[\\mathbf{x}^{\\text{m}} | \\mathbf{x}^{\\text{o}},\\mathbf{z}_{(l)}\\right] = \\sum_{l=1}^L w_l \\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z}_l)^\\text{m},\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "w_l=\\frac{r_l}{r_1+...+r_L}, \\; \\text{with} \\; r_l = \\frac{p_{\\boldsymbol{\\theta}}(\\mathbf{x}^{\\text{o}}|\\mathbf{z}_{(l)})p(\\mathbf{z}_{(l)})}{q_{\\boldsymbol{\\gamma}}(\\mathbf{z}_{(l)}|\\mathbf{x}^{\\text{o}})}.\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saR4UBU7E8IN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgivenz = tfd.Independent(\n",
        "      distribution=tfd.StudentT(loc=all_means_obs_model, scale=all_scales_obs_model, df=all_degfreedom_obs_model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZyjTXuuEX0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imp_weights = tf.nn.softmax(logpxobsgivenz + logpz - logq,0) # these are w_1,....,w_L for all observations in the batch\n",
        "xms = tf.reshape(xgivenz.mean(),[K,batch_size,p])\n",
        "xm=tf.einsum('ki,kij->ij', imp_weights, xms) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7zfAGIjHt_k",
        "colab_type": "text"
      },
      "source": [
        "# Training and imputing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTQF_6D1n4Lm",
        "colab_type": "code",
        "outputId": "d6be969e-bca8-4700-94d3-901e1ec3bb80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "miwae_loss_train=np.array([])\n",
        "mse_train=np.array([])\n",
        "bs = 64 # batch size\n",
        "n_epochs = 602\n",
        "xhat = np.copy(xhat_0) # This will be out imputed data matrix\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for ep in range(1,n_epochs):\n",
        "      perm = np.random.permutation(n) # We use the \"random reshuffling\" version of SGD\n",
        "      batches_data = np.array_split(xhat_0[perm,], n/bs)\n",
        "      batches_mask = np.array_split(mask[perm,], n/bs)\n",
        "      for it in range(len(batches_data)):\n",
        "          train_miss.run(feed_dict={x: batches_data[it], learning_rate: 0.001, K:20, xmask: batches_mask[it]}) # Gradient step      \n",
        "      if ep % 200 == 1:\n",
        "          losstrain = np.array([miwae_loss.eval(feed_dict={x: xhat_0, K:20, xmask: mask})]) # MIWAE bound evaluation\n",
        "          miwae_loss_train = np.append(miwae_loss_train,-losstrain,axis=0)\n",
        "          print('Epoch %g' %ep)\n",
        "          print('MIWAE likelihood bound  %g' %-losstrain)\n",
        "          for i in range(n): # We impute the observations one at a time for memory reasons\n",
        "              xhat[i,:][~mask[i,:]]=xm.eval(feed_dict={x: xhat_0[i,:].reshape([1,p]), K:1000, xmask: mask[i,:].reshape([1,p])})[~mask[i,:].reshape([1,p])]\n",
        "          err = np.array([mse(xhat,xfull,mask)])\n",
        "          mse_train = np.append(mse_train,err,axis=0)\n",
        "          print('Imputation MSE  %g' %err)\n",
        "          print('-----')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "MIWAE likelihood bound  -8.81285\n",
            "Imputation MSE  0.990958\n",
            "-----\n",
            "Epoch 201\n",
            "MIWAE likelihood bound  -1.86828\n",
            "Imputation MSE  0.515399\n",
            "-----\n",
            "Epoch 401\n",
            "MIWAE likelihood bound  0.488347\n",
            "Imputation MSE  0.505531\n",
            "-----\n",
            "Epoch 601\n",
            "MIWAE likelihood bound  1.23655\n",
            "Imputation MSE  0.491885\n",
            "-----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZsYAmymH28c",
        "colab_type": "text"
      },
      "source": [
        "# Comparisons with other methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84kWm6OVIRq8",
        "colab_type": "text"
      },
      "source": [
        "We make use of the recent [IterativeImputer](https://scikit-learn.org/dev/auto_examples/impute/plot_iterative_imputer_variants_comparison.html) mehod implemented in scikit-learn. It allows, in particular, to use an imputation technique quite similar to the popular missForest algorithm of  [Stekhoven & Bühlmann (2011)](https://academic.oup.com/bioinformatics/article/28/1/112/219101)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQMQZzoqEXxw",
        "colab_type": "code",
        "outputId": "d4cd536d-d6b6-4661-d3aa-b94beade6830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "missforest = IterativeImputer(estimator=ExtraTreesRegressor(n_estimators=100))\n",
        "missforest.fit(xmiss)\n",
        "xhat_mf = missforest.transform(xmiss)\n",
        "mean_imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "mean_imp.fit(xmiss)\n",
        "xhat_mean = mean_imp.transform(xmiss)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/impute/_iterative.py:599: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  \" reached.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF3VgTEGEXu-",
        "colab_type": "code",
        "outputId": "e7616e01-2f91-4f28-ffc9-0eca95ce2c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(range(1,n_epochs,200),mse_train,color=\"blue\")\n",
        "plt.axhline(y=mse(xhat_mf,xfull,mask),  linestyle='-',color=\"red\")\n",
        "plt.axhline(y=mse(xhat_mean,xfull,mask),  linestyle='-',color=\"orange\")\n",
        "plt.legend([\"MIWAE\",\"missForest\",\"Mean\"])\n",
        "plt.title(\"Imputation MSE\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}